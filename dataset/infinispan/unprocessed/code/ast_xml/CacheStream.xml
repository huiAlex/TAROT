<Class>
    <Id>1274</Id>
    <Package>org.infinispan</Package>
    <ClassName>CacheStream</ClassName>
    <SuperClass></SuperClass>
    <SuperInterfaceList>
        <SuperInterface>Stream</SuperInterface>
        <SuperInterface>R</SuperInterface>
        <SuperInterface>BaseCacheStream</SuperInterface>
        <SuperInterface>R</SuperInterface>
    </SuperInterfaceList>
    <ClassComment>CacheStream  /** 
 * A  {@link Stream} that has additional operations to monitor or control behavior when used from a {@link Cache}. &lt;p&gt;Whenever the iterator or spliterator methods are used the user &lt;b&gt;must&lt;/b&gt; close the  {@link Stream}that the method was invoked on after completion of its operation.  Failure to do so may cause a thread leakage if the iterator or spliterator are not fully consumed.&lt;/p&gt; &lt;p&gt;When using stream that is backed by a distributed cache these operations will be performed using remote distribution controlled by the segments that each key maps to.  All intermediate operations are lazy, even the special cases described in later paragraphs and are not evaluated until a final terminal operation is invoked on the stream.  Essentially each set of intermediate operations is shipped to each remote node where they are applied to a local stream there and finally the terminal operation is completed.  If this stream is parallel the processing on remote nodes is also done using a parallel stream.&lt;/p&gt; &lt;p&gt;Parallel distribution is enabled by default for all operations except for  {@link CacheStream#iterator()} &amp;{@link CacheStream#spliterator()}.  Please see  {@link CacheStream#sequentialDistribution()} and{@link CacheStream#parallelDistribution()}.  With this disabled only a single node will process the operation at a time (includes locally).&lt;/p&gt; &lt;p&gt;Rehash aware is enabled by default for all operations.  Any intermediate or terminal operation may be invoked multiple times during a rehash and thus you should ensure the are idempotent.  This can be problematic for {@link CacheStream#forEach(Consumer)} as it may be difficult to implement with such requirements, please see it formore information.  If you wish to disable rehash aware operations you can disable them by calling {@link CacheStream#disableRehashAware()} which should provide better performance for some operations.  Theperformance is most affected for the key aware operations  {@link CacheStream#iterator()}, {@link CacheStream#spliterator()},  {@link CacheStream#forEach(Consumer)}.  Disabling rehash can cause incorrect results if the terminal operation is invoked and a rehash occurs before the operation completes.  If incorrect results do occur it is guaranteed that it will only be that entries were missed and no entries are duplicated.&lt;/p&gt; &lt;p&gt;Any stateful intermediate operation requires pulling all information up to that point local to operate properly. Each of these methods may have slightly different behavior, so make sure you check the method you are utilizing.&lt;/p&gt; &lt;p&gt;An example of such an operation is using distinct intermediate operation. What will happen is upon calling the terminal operation a remote retrieval operation will be ran using all of the intermediate operations up to the distinct operation remotely.  This retrieval is then used to fuel a local stream where all of the remaining intermediate operations are performed and then finally the terminal operation is applied as normal.  Note in this case the intermediate iterator still obeys the {@link CacheStream#distributedBatchSize(int)} setting irrespective of the terminal operator.&lt;/p&gt;
 * @param &lt; R &gt; The type of the stream
 * @since 8.0
 */
</ClassComment>
    <FieldList/>
    <MethodList>
        <Method>
            <MethodName>sequentialDistribution</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}
 * @return a stream with parallel distribution disabled.
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList/>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>parallelDistribution</MethodName>
            <MethodComment>/** 
 * @inheritDoc
 * @return a stream with parallel distribution enabled.
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList/>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>filterKeySegments</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}
 * @return a stream with the segments filtered.
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>segments</ParamName>
                    <ParamType>Integer</ParamType>
                </Parameter>
            </ParameterList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>filterKeys</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}
 * @return a stream with the keys filtered.
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>keys</ParamName>
                    <ParamType>?</ParamType>
                </Parameter>
            </ParameterList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>distributedBatchSize</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}
 * @return a stream with the batch size updated
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>batchSize</ParamName>
                    <ParamType>int</ParamType>
                </Parameter>
            </ParameterList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>segmentCompletionListener</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}
 * @return a stream with the listener registered.
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>listener</ParamName>
                    <ParamType>SegmentCompletionListener</ParamType>
                </Parameter>
            </ParameterList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>disableRehashAware</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}
 * @return a stream with rehash awareness disabled.
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList/>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>timeout</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}
 * @return a stream with the timeout set
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>timeout</ParamName>
                    <ParamType>long</ParamType>
                </Parameter>
                <Parameter>
                    <ParamName>unit</ParamName>
                    <ParamType>TimeUnit</ParamType>
                </Parameter>
            </ParameterList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>forEach</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}&lt;p&gt;This operation is performed remotely on the node that is the primary owner for the key tied to the entry(s) in this stream.&lt;/p&gt; &lt;p&gt;NOTE: This method while being rehash aware has the lowest consistency of all of the operators.  This operation will be performed on every entry at least once in the cluster, as long as the originator doesn't go down while it is being performed.  This is due to how the distributed action is performed.  Essentially the {@link CacheStream#distributedBatchSize} value controls how many elements are processed per node at a timewhen rehash is enabled. After those are complete the keys are sent to the originator to confirm that those were processed.  If that node goes down during/before the response those keys will be processed a second time.&lt;/p&gt; &lt;p&gt;It is possible to have the cache local to each node injected into this instance if the provided Consumer also implements the  {@link org.infinispan.stream.CacheAware} interface.  This method will be invokedbefore the consumer &lt;code&gt;accept()&lt;/code&gt; method is invoked.&lt;/p&gt; &lt;p&gt;This method is ran distributed by default with a distributed backing cache.  However if you wish for this operation to run locally you can use the  {@code stream().iterator().forEachRemaining(action)} for a singlethreaded variant.  If you wish to have a parallel variant you can use  {@link java.util.stream.StreamSupport#stream(Spliterator,boolean)}passing in the spliterator from the stream.  In either case remember you &lt;b&gt;must&lt;/b&gt; close the stream after you are done processing the iterator or spliterator..&lt;/p&gt;
 * @param action consumer to be ran for each element in the stream
 */
</MethodComment>
            <ReturnType>void</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>action</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>forEach</MethodName>
            <MethodComment>/** 
 * Same as  {@link CacheStream#forEach(Consumer)} except that the Consumer must alsoimplement &lt;code&gt;Serializable&lt;/code&gt; &lt;p&gt; The compiler will pick this overload for lambda parameters, making them &lt;code&gt;Serializable&lt;/code&gt;
 * @param action consumer to be ran for each element in the stream
 */
</MethodComment>
            <ReturnType>void</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>action</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke>null;forEach;[(Consumer&lt;? super R&gt;)action]</InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>forEach</MethodName>
            <MethodComment>/** 
 * Same as  {@link CacheStream#forEach(Consumer)} except that it takes a {@link BiConsumer} that provides accessto the underlying  {@link Cache} that is backing this stream.&lt;p&gt; Note that the &lt;code&gt;CacheAware&lt;/code&gt; interface is not supported for injection using this method as the cache is provided in the consumer directly.
 * @param action consumer to be ran for each element in the stream
 * @param &lt; K &gt; key type of the cache
 * @param &lt; V &gt; value type of the cache
 */
</MethodComment>
            <ReturnType>void</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>action</ParamName>
                    <ParamType>Cache&lt;K,V&gt;</ParamType>
                </Parameter>
            </ParameterList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>forEach</MethodName>
            <MethodComment>/** 
 * Same as  {@link CacheStream#forEach(BiConsumer)} except that the &lt;code&gt;BiConsumer&lt;/code&gt; must also implement&lt;code&gt;Serializable&lt;/code&gt;
 * @param action consumer to be ran for each element in the stream
 * @param &lt; K &gt; key type of the cache
 * @param &lt; V &gt; value type of the cache
 */
</MethodComment>
            <ReturnType>void</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>action</ParamName>
                    <ParamType>Cache&lt;K,V&gt;</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke>null;forEach;[(BiConsumer&lt;Cache&lt;K,V&gt;,? super R&gt;)action]</InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>iterator</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}&lt;p&gt;Usage of this operator requires closing this stream after you are done with the iterator.  The preferred usage is to use a try with resource block on the stream.&lt;/p&gt; &lt;p&gt;This method has special usage with the  {@link org.infinispan.CacheStream.SegmentCompletionListener} inthat as entries are retrieved from the next method it will complete segments.&lt;/p&gt; &lt;p&gt;This method obeys the  {@link CacheStream#distributedBatchSize(int)}.  Note that when using methods such as {@link CacheStream#flatMap(Function)} that you will have possibly more than 1 element mapped to a given keyso this doesn't guarantee that many number of entries are returned per batch.&lt;/p&gt; &lt;p&gt;Note that the  {@link Iterator#remove()} method is only supported if no intermediate operations have beenapplied to the stream and this is not a stream created from a  {@link Cache#values()} collection.&lt;/p&gt;
 * @return the element iterator for this stream
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList/>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>spliterator</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}&lt;p&gt;Usage of this operator requires closing this stream after you are done with the spliterator.  The preferred usage is to use a try with resource block on the stream.&lt;/p&gt;
 * @return the element spliterator for this stream
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList/>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>sorted</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}&lt;p&gt;This operation is performed entirely on the local node irrespective of the backing cache.  This operation will act as an intermediate iterator operation requiring data be brought locally for proper behavior. Beware this means it will require having all entries of this cache into memory at one time.  This is described in more detail at  {@link CacheStream}&lt;/p&gt; &lt;p&gt;Any subsequent intermediate operations and the terminal operation are also performed locally.&lt;/p&gt;
 * @return the new stream
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList/>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>sorted</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}&lt;p&gt;This operation is performed entirely on the local node irrespective of the backing cache.  This operation will act as an intermediate iterator operation requiring data be brought locally for proper behavior. Beware this means it will require having all entries of this cache into memory at one time.  This is described in more detail at  {@link CacheStream}&lt;/p&gt; &lt;p&gt;Any subsequent intermediate operations and the terminal operation are then performed locally.&lt;/p&gt;
 * @param comparator the comparator to be used for sorting the elements
 * @return the new stream
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>comparator</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>sorted</MethodName>
            <MethodComment>/** 
 * Same as  {@link CacheStream#sorted(Comparator)} except that the Comparator mustalso implement &lt;code&gt;Serializable&lt;/code&gt; &lt;p&gt; The compiler will pick this overload for lambda parameters, making them &lt;code&gt;Serializable&lt;/code&gt;
 * @param comparator a non-interfering, stateless{@code Comparator} to be used to compare stream elements
 * @return the new stream
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>comparator</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>limit</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}&lt;p&gt;This intermediate operation will be performed both remotely and locally to reduce how many elements are sent back from each node.  More specifically this operation is applied remotely on each node to only return up to the &lt;b&gt;maxSize&lt;/b&gt; value and then the aggregated results are limited once again on the local node.&lt;/p&gt; &lt;p&gt;This operation will act as an intermediate iterator operation requiring data be brought locally for proper behavior.  This is described in more detail in the  {@link CacheStream} documentation&lt;/p&gt;&lt;p&gt;Any subsequent intermediate operations and the terminal operation are then performed locally.&lt;/p&gt;
 * @param maxSize how many elements to limit this stream to.
 * @return the new stream
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>maxSize</ParamName>
                    <ParamType>long</ParamType>
                </Parameter>
            </ParameterList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>skip</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}&lt;p&gt;This operation is performed entirely on the local node irrespective of the backing cache.  This operation will act as an intermediate iterator operation requiring data be brought locally for proper behavior. This is described in more detail in the  {@link CacheStream} documentation&lt;/p&gt;&lt;p&gt;Depending on the terminal operator this may or may not require all entries or a subset after skip is applied to be in memory all at once.&lt;/p&gt; &lt;p&gt;Any subsequent intermediate operations and the terminal operation are then performed locally.&lt;/p&gt;
 * @param n how many elements to skip from this stream
 * @return the new stream
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>n</ParamName>
                    <ParamType>long</ParamType>
                </Parameter>
            </ParameterList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>peek</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}
 * @param action the action to perform on the stream
 * @return the new stream
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>action</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>peek</MethodName>
            <MethodComment>/** 
 * Same as  {@link CacheStream#peek(Consumer)} except that the Consumer must also implement &lt;code&gt;Serializable&lt;/code&gt;&lt;p&gt; The compiler will pick this overload for lambda parameters, making them &lt;code&gt;Serializable&lt;/code&gt;
 * @param action a non-interfering action to perform on the elements asthey are consumed from the stream
 * @return the new stream
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>action</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>distinct</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}&lt;p&gt;This operation will be invoked both remotely and locally when used with a distributed cache backing this stream. This operation will act as an intermediate iterator operation requiring data be brought locally for proper behavior.  This is described in more detail in the  {@link CacheStream} documentation&lt;/p&gt;&lt;p&gt;This intermediate iterator operation will be performed locally and remotely requiring possibly a subset of all elements to be in memory&lt;/p&gt; &lt;p&gt;Any subsequent intermediate operations and the terminal operation are then performed locally.&lt;/p&gt;
 * @return the new stream
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList/>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>collect</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}&lt;p&gt;Note when using a distributed backing cache for this stream the collector must be marshallable.  This prevents the usage of  {@link java.util.stream.Collectors} class.  However you can use the{@link org.infinispan.stream.CacheCollectors} static factory methods to create a serializable wrapper, which thencreates the actual collector lazily after being deserialized.  This is useful to use any method from the {@link java.util.stream.Collectors} class as you would normally.Alternatively, you can call  {@link #collect(SerializableSupplier)} too.&lt;/p&gt;
 * @param collector
 * @param &lt; R1 &gt; collected type
 * @param &lt; A &gt; intermediate collected type if applicable
 * @return the collected value
 * @see org.infinispan.stream.CacheCollectors
 */
</MethodComment>
            <ReturnType>R1</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>collector</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>collect</MethodName>
            <MethodComment>/** 
 * Performs a &lt;a href="package-summary.html#MutableReduction"&gt;mutable reduction&lt;/a&gt; operation on the elements of this stream using a {@code Collector} that is lazily created from the {@code SerializableSupplier}provided. This method behaves exactly the same as  {@link #collect(Collector)} withthe enhanced capability of working even when the mutable reduction operation has to run in a remote node and the operation is not {@link Serializable} or otherwise marshallable.So, this method is specially designed for situations when the user wants to use a  {@link Collector} instance that has been created by{@link java.util.stream.Collectors} static factory methods.In this particular case, the function that instantiates the {@link Collector} will be marshalled according to the{@link Serializable} rules.
 * @param supplier The supplier to create the collector that is specifically serializable
 * @param &lt; R1 &gt; The resulting type of the collector
 * @return the collected value
 * @since 9.2
 */
</MethodComment>
            <ReturnType>R1</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>supplier</ParamName>
                    <ParamType>Collector&lt;? super R,?,R1&gt;</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>collect</MethodName>
            <MethodComment>/** 
 * Performs a &lt;a href="package-summary.html#MutableReduction"&gt;mutable reduction&lt;/a&gt; operation on the elements of this stream using a {@code Collector} that is lazily created from the {@code Supplier}provided. This method behaves exactly the same as  {@link #collect(Collector)} withthe enhanced capability of working even when the mutable reduction operation has to run in a remote node and the operation is not {@link Serializable} or otherwise marshallable.So, this method is specially designed for situations when the user wants to use a  {@link Collector} instance that has been created by{@link java.util.stream.Collectors} static factory methods.In this particular case, the function that instantiates the {@link Collector} will be marshalled using Infinispan{@link org.infinispan.commons.marshall.Externalizer} class or one of itssubtypes.
 * @param supplier The supplier to create the collector
 * @param &lt; R1 &gt; The resulting type of the collector
 * @return the collected value
 * @since 9.2
 */
</MethodComment>
            <ReturnType>R1</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>supplier</ParamName>
                    <ParamType>Collector&lt;? super R,?,R1&gt;</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>collect</MethodName>
            <MethodComment>/** 
 * Same as  {@link CacheStream#collect(Supplier,BiConsumer,BiConsumer)} except that the various arguments mustalso implement &lt;code&gt;Serializable&lt;/code&gt; &lt;p&gt; The compiler will pick this overload for lambda parameters, making them &lt;code&gt;Serializable&lt;/code&gt;
 * @param &lt; R1 &gt; type of the result
 * @param supplier a function that creates a new result container. For aparallel execution, this function may be called multiple times and must return a fresh value each time. Must be serializable
 * @param accumulator an associative, non-interfering, statelessfunction for incorporating an additional element into a result and must be serializable
 * @param combiner an associative, non-interfering, statelessfunction for combining two values, which must be compatible with the accumulator function and serializable
 * @return the result of the reduction
 */
</MethodComment>
            <ReturnType>R1</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>supplier</ParamName>
                    <ParamType>R1</ParamType>
                </Parameter>
                <Parameter>
                    <ParamName>accumulator</ParamName>
                    <ParamType>R1</ParamType>
                </Parameter>
                <Parameter>
                    <ParamName>combiner</ParamName>
                    <ParamType>R1</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>allMatch</MethodName>
            <MethodComment>/** 
 * Same as  {@link CacheStream#allMatch(Predicate)} except that the Predicate must alsoimplement &lt;code&gt;Serializable&lt;/code&gt; &lt;p&gt; The compiler will pick this overload for lambda parameters, making them &lt;code&gt;Serializable&lt;/code&gt;
 * @param predicate a non-interfering, statelesspredicate to apply to elements of this stream that is serializable
 * @return {@code true} if either all elements of the stream match theprovided predicate or the stream is empty, otherwise  {@code false}
 */
</MethodComment>
            <ReturnType>boolean</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>predicate</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>noneMatch</MethodName>
            <MethodComment>/** 
 * Same as  {@link CacheStream#noneMatch(Predicate)} except that the Predicate must alsoimplement &lt;code&gt;Serializable&lt;/code&gt; &lt;p&gt; The compiler will pick this overload for lambda parameters, making them &lt;code&gt;Serializable&lt;/code&gt;
 * @param predicate a non-interfering, statelesspredicate to apply to elements of this stream that is serializable
 * @return {@code true} if either no elements of the stream match theprovided predicate or the stream is empty, otherwise  {@code false}
 */
</MethodComment>
            <ReturnType>boolean</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>predicate</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>anyMatch</MethodName>
            <MethodComment>/** 
 * Same as  {@link CacheStream#anyMatch(Predicate)} except that the Predicate must alsoimplement &lt;code&gt;Serializable&lt;/code&gt; &lt;p&gt; The compiler will pick this overload for lambda parameters, making them &lt;code&gt;Serializable&lt;/code&gt;
 * @param predicate a non-interfering, statelesspredicate to apply to elements of this stream that is serializable
 * @return {@code true} if any elements of the stream match the providedpredicate, otherwise  {@code false}
 */
</MethodComment>
            <ReturnType>boolean</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>predicate</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>max</MethodName>
            <MethodComment>/** 
 * Same as  {@link CacheStream#max(Comparator)} except that the Comparator must alsoimplement &lt;code&gt;Serializable&lt;/code&gt; &lt;p&gt; The compiler will pick this overload for lambda parameters, making them &lt;code&gt;Serializable&lt;/code&gt;
 * @param comparator a non-interfering, stateless{@code Comparator} to compare elements of this stream that is also serializable
 * @return an {@code Optional} describing the maximum element of this stream,or an empty  {@code Optional} if the stream is empty
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>comparator</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>min</MethodName>
            <MethodComment>/** 
 * Same as  {@link CacheStream#min(Comparator)} except that the Comparator must alsoimplement &lt;code&gt;Serializable&lt;/code&gt; &lt;p&gt; The compiler will pick this overload for lambda parameters, making them &lt;code&gt;Serializable&lt;/code&gt;
 * @param comparator a non-interfering, stateless{@code Comparator} to compare elements of this stream that is also serializable
 * @return an {@code Optional} describing the minimum element of this stream,or an empty  {@code Optional} if the stream is empty
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>comparator</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>reduce</MethodName>
            <MethodComment>/** 
 * Same as  {@link CacheStream#reduce(BinaryOperator)} except that the BinaryOperator must alsoimplement &lt;code&gt;Serializable&lt;/code&gt; &lt;p&gt; The compiler will pick this overload for lambda parameters, making them &lt;code&gt;Serializable&lt;/code&gt;
 * @param accumulator an associative, non-interfering, statelessfunction for combining two values that is also serializable
 * @return an {@link Optional} describing the result of the reduction
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>accumulator</ParamName>
                    <ParamType>R</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>reduce</MethodName>
            <MethodComment>/** 
 * Same as  {@link CacheStream#reduce(Object,BinaryOperator)}  except that the BinaryOperator must alsoimplement &lt;code&gt;Serializable&lt;/code&gt; &lt;p&gt; The compiler will pick this overload for lambda parameters, making them &lt;code&gt;Serializable&lt;/code&gt;
 * @param identity the identity value for the accumulating function
 * @param accumulator an associative, non-interfering, statelessfunction for combining two values that is also serializable
 * @return the result of the reduction
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>identity</ParamName>
                    <ParamType>R</ParamType>
                </Parameter>
                <Parameter>
                    <ParamName>accumulator</ParamName>
                    <ParamType>R</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>reduce</MethodName>
            <MethodComment>/** 
 * Same as  {@link CacheStream#reduce(Object,BiFunction,BinaryOperator)} except that the BinaryOperator must alsoimplement &lt;code&gt;Serializable&lt;/code&gt; &lt;p&gt; The compiler will pick this overload for lambda parameters, making them &lt;code&gt;Serializable&lt;/code&gt;
 * @param &lt; U &gt; The type of the result
 * @param identity the identity value for the combiner function
 * @param accumulator an associative, non-interfering, statelessfunction for incorporating an additional element into a result  that is also serializable
 * @param combiner an associative, non-interfering, statelessfunction for combining two values, which must be compatible with the accumulator function that is also serializable
 * @return the result of the reduction
 */
</MethodComment>
            <ReturnType>U</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>identity</ParamName>
                    <ParamType>U</ParamType>
                </Parameter>
                <Parameter>
                    <ParamName>accumulator</ParamName>
                    <ParamType>U</ParamType>
                </Parameter>
                <Parameter>
                    <ParamName>combiner</ParamName>
                    <ParamType>U</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>toArray</MethodName>
            <MethodComment>/** 
 * Same as  {@link CacheStream#toArray(IntFunction)} except that the BinaryOperator must alsoimplement &lt;code&gt;Serializable&lt;/code&gt; &lt;p&gt; The compiler will pick this overload for lambda parameters, making them &lt;code&gt;Serializable&lt;/code&gt;
 * @param &lt; A &gt; the element type of the resulting array
 * @param generator a function which produces a new array of the desiredtype and the provided length that is also serializable
 * @return an array containing the elements in this stream
 */
</MethodComment>
            <ReturnType>A[]</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>generator</ParamName>
                    <ParamType>A[]</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>filter</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}
 * @return the new cache stream
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>predicate</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>filter</MethodName>
            <MethodComment>/** 
 * Same as  {@link CacheStream#filter(Predicate)} except that the Predicate must alsoimplement &lt;code&gt;Serializable&lt;/code&gt; &lt;p&gt; The compiler will pick this overload for lambda parameters, making them &lt;code&gt;Serializable&lt;/code&gt;
 * @param predicate a non-interfering, statelesspredicate to apply to each element to determine if it should be included
 * @return the new cache stream
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>predicate</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>map</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}
 * @return the new cache stream
 */
</MethodComment>
            <ReturnType>R1</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>mapper</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>map</MethodName>
            <MethodComment>/** 
 * Same as  {@link CacheStream#map(Function)} except that the Function must alsoimplement &lt;code&gt;Serializable&lt;/code&gt; &lt;p&gt; The compiler will pick this overload for lambda parameters, making them &lt;code&gt;Serializable&lt;/code&gt;
 * @param &lt; R1 &gt; The element type of the new stream
 * @param mapper a non-interfering, statelessfunction to apply to each element
 * @return the new cache stream
 */
</MethodComment>
            <ReturnType>R1</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>mapper</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>mapToDouble</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}
 * @param mapper a non-interfering, statelessfunction to apply to each element
 * @return the new double cache stream
 */
</MethodComment>
            <ReturnType>DoubleCacheStream</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>mapper</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>mapToDouble</MethodName>
            <MethodComment>/** 
 * Same as  {@link CacheStream#mapToDouble(ToDoubleFunction)}  except that the ToDoubleFunction must alsoimplement &lt;code&gt;Serializable&lt;/code&gt; &lt;p&gt; The compiler will pick this overload for lambda parameters, making them &lt;code&gt;Serializable&lt;/code&gt;
 * @param mapper a non-interfering, statelessfunction to apply to each element
 * @return the new stream
 */
</MethodComment>
            <ReturnType>DoubleCacheStream</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>mapper</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>mapToInt</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}
 * @param mapper a non-interfering, statelessfunction to apply to each element
 * @return the new int cache stream
 */
</MethodComment>
            <ReturnType>IntCacheStream</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>mapper</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>mapToInt</MethodName>
            <MethodComment>/** 
 * Same as  {@link CacheStream#mapToInt(ToIntFunction)}  except that the ToIntFunction must alsoimplement &lt;code&gt;Serializable&lt;/code&gt; &lt;p&gt; The compiler will pick this overload for lambda parameters, making them &lt;code&gt;Serializable&lt;/code&gt;
 * @param mapper a non-interfering, statelessfunction to apply to each element
 * @return the new stream
 */
</MethodComment>
            <ReturnType>IntCacheStream</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>mapper</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>mapToLong</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}
 * @param mapper a non-interfering, statelessfunction to apply to each element
 * @return the new long cache stream
 */
</MethodComment>
            <ReturnType>LongCacheStream</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>mapper</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>mapToLong</MethodName>
            <MethodComment>/** 
 * Same as  {@link CacheStream#mapToLong(ToLongFunction)}  except that the ToLongFunction must alsoimplement &lt;code&gt;Serializable&lt;/code&gt; &lt;p&gt; The compiler will pick this overload for lambda parameters, making them &lt;code&gt;Serializable&lt;/code&gt;
 * @param mapper a non-interfering, statelessfunction to apply to each element
 * @return the new stream
 */
</MethodComment>
            <ReturnType>LongCacheStream</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>mapper</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>flatMap</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}
 * @return the new cache stream
 */
</MethodComment>
            <ReturnType>R1</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>mapper</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>flatMap</MethodName>
            <MethodComment>/** 
 * Same as  {@link CacheStream#flatMap(Function)} except that the Function must alsoimplement &lt;code&gt;Serializable&lt;/code&gt; &lt;p&gt; The compiler will pick this overload for lambda parameters, making them &lt;code&gt;Serializable&lt;/code&gt;
 * @param &lt; R1 &gt; The element type of the new stream
 * @param mapper a non-interfering, statelessfunction to apply to each element which produces a stream of new values
 * @return the new cache stream
 */
</MethodComment>
            <ReturnType>R1</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>mapper</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>flatMapToDouble</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}
 * @return the new cache stream
 */
</MethodComment>
            <ReturnType>DoubleCacheStream</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>mapper</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>flatMapToDouble</MethodName>
            <MethodComment>/** 
 * Same as  {@link CacheStream#flatMapToDouble(Function)} except that the Function must alsoimplement &lt;code&gt;Serializable&lt;/code&gt; &lt;p&gt; The compiler will pick this overload for lambda parameters, making them &lt;code&gt;Serializable&lt;/code&gt;
 * @param mapper a non-interfering, statelessfunction to apply to each element which produces a stream of new values
 * @return the new stream
 */
</MethodComment>
            <ReturnType>DoubleCacheStream</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>mapper</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>flatMapToInt</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}
 * @return the new cache stream
 */
</MethodComment>
            <ReturnType>IntCacheStream</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>mapper</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>flatMapToInt</MethodName>
            <MethodComment>/** 
 * Same as  {@link CacheStream#flatMapToInt(Function)} except that the Function must alsoimplement &lt;code&gt;Serializable&lt;/code&gt; &lt;p&gt; The compiler will pick this overload for lambda parameters, making them &lt;code&gt;Serializable&lt;/code&gt;
 * @param mapper a non-interfering, statelessfunction to apply to each element which produces a stream of new values
 * @return the new stream
 */
</MethodComment>
            <ReturnType>IntCacheStream</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>mapper</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>flatMapToLong</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}
 * @return the new cache stream
 */
</MethodComment>
            <ReturnType>LongCacheStream</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>mapper</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>flatMapToLong</MethodName>
            <MethodComment>/** 
 * Same as  {@link CacheStream#flatMapToLong(Function)} except that the Function must alsoimplement &lt;code&gt;Serializable&lt;/code&gt; &lt;p&gt; The compiler will pick this overload for lambda parameters, making them &lt;code&gt;Serializable&lt;/code&gt;
 * @param mapper a non-interfering, statelessfunction to apply to each element which produces a stream of new values
 * @return the new stream
 */
</MethodComment>
            <ReturnType>LongCacheStream</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>mapper</ParamName>
                    <ParamType>? super R</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>parallel</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}
 * @return a parallel cache stream
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList/>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>sequential</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}
 * @return a sequential cache stream
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList/>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>unordered</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}
 * @return an unordered cache stream
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList/>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>onClose</MethodName>
            <MethodComment>/** 
 * {@inheritDoc}
 * @param closeHandler
 * @return a cache stream with the handler applied
 */
</MethodComment>
            <ReturnType>R</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>closeHandler</ParamName>
                    <ParamType>Runnable</ParamType>
                </Parameter>
            </ParameterList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
    </MethodList>
</Class>