<Class>
    <Id>514</Id>
    <Package>org.apache.pig</Package>
    <ClassName>LoadFunc</ClassName>
    <SuperClass></SuperClass>
    <SuperInterfaceList>
        <SuperInterface></SuperInterface>
    </SuperInterfaceList>
    <ClassComment>LoadFunc  /** 
 * A LoadFunc loads data into Pig.  It can read from an HDFS file or other source. LoadFunc is tightly coupled to Hadoop's  {@link org.apache.hadoop.mapreduce.InputFormat}. LoadFunc's sit atop an InputFormat and translate from the keys and values of Hadoop to Pig's tuples.   &lt;p&gt; LoadFunc contains the basic features needed by the majority of load functions.  For more advanced functionality there are separate interfaces that a load function can implement.  See  {@link LoadCaster},  {@link LoadMetadata},  {@link LoadPushDown},  {@link OrderedLoadFunc},  {@link CollectableLoadFunc}, and  {@link IndexableLoadFunc}.
 */
</ClassComment>
    <FieldList/>
    <MethodList>
        <Method>
            <MethodName>relativeToAbsolutePath</MethodName>
            <MethodComment>/** 
 * This method is called by the Pig runtime in the front end to convert the input location to an absolute path if the location is relative. The loadFunc implementation is free to choose how it converts a relative  location to an absolute location since this may depend on what the location string represent (hdfs path or some other data source)
 * @param location location as provided in the "load" statement of the script
 * @param curDir the current working direction based on any "cd" statementsin the script before the "load" statement. If there are no "cd" statements in the script, this would be the home directory -  &lt;pre&gt;/user/&lt;username&gt; &lt;/pre&gt;
 * @return the absolute location based on the arguments passed
 * @throws IOException if the conversion is not possible
 */
</MethodComment>
            <ReturnType>String</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>location</ParamName>
                    <ParamType>String</ParamType>
                </Parameter>
                <Parameter>
                    <ParamName>curDir</ParamName>
                    <ParamType>Path</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType>IOException</ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>setLocation</MethodName>
            <MethodComment>/** 
 * Communicate to the loader the location of the object(s) being loaded.   The location string passed to the LoadFunc here is the return value of  {@link LoadFunc#relativeToAbsolutePath(String,Path)}. Implementations should use this method to communicate the location (and any other information) to its underlying InputFormat through the Job object. This method will be called in the frontend and backend multiple times. Implementations should bear in mind that this method is called multiple times and should ensure there are no inconsistent side effects due to the multiple calls.
 * @param location Location as returned by {@link LoadFunc#relativeToAbsolutePath(String,Path)}
 * @param job the {@link Job} objectstore or retrieve earlier stored information from the  {@link UDFContext}
 * @throws IOException if the location is not valid.
 */
</MethodComment>
            <ReturnType>void</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>location</ParamName>
                    <ParamType>String</ParamType>
                </Parameter>
                <Parameter>
                    <ParamName>job</ParamName>
                    <ParamType>Job</ParamType>
                </Parameter>
            </ParameterList>
            <ThrowExceptionList>
                <ExceptionType>IOException</ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>getInputFormat</MethodName>
            <MethodComment>/** 
 * This will be called during planning on the front end. This is the instance of InputFormat (rather than the class name) because the  load function may need to instantiate the InputFormat in order  to control how it is constructed.
 * @return the InputFormat associated with this loader.
 * @throws IOException if there is an exception during InputFormat construction
 */
</MethodComment>
            <ReturnType>InputFormat</ReturnType>
            <ParameterList/>
            <ThrowExceptionList>
                <ExceptionType>IOException</ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>getLoadCaster</MethodName>
            <MethodComment>/** 
 * This will be called on both the front end and the back end during execution.
 * @return the {@link LoadCaster} associated with this loader. Returning null indicates that casts from byte array are not supported for this loader.  construction
 * @throws IOException if there is an exception during LoadCaster 
 */
</MethodComment>
            <ReturnType>LoadCaster</ReturnType>
            <ParameterList/>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType>IOException</ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>prepareToRead</MethodName>
            <MethodComment>/** 
 * Initializes LoadFunc for reading data.  This will be called during execution before any calls to getNext.  The RecordReader needs to be passed here because it has been instantiated for a particular InputSplit.
 * @param reader {@link RecordReader} to be used by this instance of the LoadFunc
 * @param split The input {@link PigSplit} to process
 * @throws IOException if there is an exception during initialization
 */
</MethodComment>
            <ReturnType>void</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>reader</ParamName>
                    <ParamType>RecordReader</ParamType>
                </Parameter>
                <Parameter>
                    <ParamName>split</ParamName>
                    <ParamType>PigSplit</ParamType>
                </Parameter>
            </ParameterList>
            <ThrowExceptionList>
                <ExceptionType>IOException</ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>getNext</MethodName>
            <MethodComment>/** 
 * Retrieves the next tuple to be processed. Implementations should NOT reuse tuple objects (or inner member objects) they return across calls and  should return a different tuple object in each call.
 * @return the next tuple to be processed or null if there are no more tuplesto be processed.
 * @throws IOException if there is an exception while retrieving the nexttuple
 */
</MethodComment>
            <ReturnType>Tuple</ReturnType>
            <ParameterList/>
            <ThrowExceptionList>
                <ExceptionType>IOException</ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>join</MethodName>
            <MethodComment>/** 
 * Join multiple strings into a string delimited by the given delimiter.
 * @param s a collection of strings
 * @param delimiter the delimiter 
 * @return a 'delimiter' separated string
 */
</MethodComment>
            <ReturnType>String</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>s</ParamName>
                    <ParamType>String</ParamType>
                </Parameter>
                <Parameter>
                    <ParamName>delimiter</ParamName>
                    <ParamType>String</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar>Iterator&lt;String&gt; [iter=s.iterator()]</InnerVar>
                <InnerVar>StringBuffer [buffer=new StringBuffer(iter.next())]</InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>getPathStrings</MethodName>
            <MethodComment>/** 
 * Parse comma separated path strings into a string array. This method  escapes commas in the Hadoop glob pattern of the given paths.  This method is borrowed from  {@link org.apache.hadoop.mapreduce.lib.input.FileInputFormat}. A jira (MAPREDUCE-1205) is opened to make the same name method there  accessible. We'll use that method directly when the jira is fixed.
 * @param commaSeparatedPaths a comma separated string
 * @return an array of path strings
 */
</MethodComment>
            <ReturnType>String[]</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>commaSeparatedPaths</ParamName>
                    <ParamType>String</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar>int [length=commaSeparatedPaths.length()]</InnerVar>
                <InnerVar>int [curlyOpen=0]</InnerVar>
                <InnerVar>int [pathStart=0]</InnerVar>
                <InnerVar>boolean [globPattern=false]</InnerVar>
                <InnerVar>List&lt;String&gt; [pathStrings=new ArrayList&lt;String&gt;()]</InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke>pathStrings;add;[commaSeparatedPaths.substring(pathStart,length)]</InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>getAbsolutePath</MethodName>
            <MethodComment>/** 
 * Construct the absolute path from the file location and the current directory. The current directory is either of the form  {code}hdfs://&lt;nodename&gt;:&lt;nodeport&gt;/&lt;directory&gt;{code} in Hadoop  MapReduce mode, or of the form  {code}file:///&lt;directory&gt;{code} in Hadoop local mode.
 * @param location the location string specified in the load statement
 * @param curDir the current file system directory
 * @return the absolute path of file in the file system
 * @throws FrontendException if the scheme of the location is incompatiblewith the scheme of the file system
 */
</MethodComment>
            <ReturnType>String</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>location</ParamName>
                    <ParamType>String</ParamType>
                </Parameter>
                <Parameter>
                    <ParamName>curDir</ParamName>
                    <ParamType>Path</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar>URI [fsUri=curDir.toUri()]</InnerVar>
                <InnerVar>String [fsScheme=fsUri.getScheme()]</InnerVar>
                <InnerVar>String [authority=fsUri.getAuthority()]</InnerVar>
                <InnerVar>Path [rootDir=new Path(fsScheme,authority,"/")]</InnerVar>
                <InnerVar>ArrayList&lt;String&gt; [pathStrings=new ArrayList&lt;String&gt;()]</InnerVar>
                <InnerVar>String[] [fnames=getPathStrings(location)]</InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType>FrontendException</ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>setUDFContextSignature</MethodName>
            <MethodComment>/** 
 * This method will be called by Pig both in the front end and back end to pass a unique signature to the  {@link LoadFunc}. The signature can be used to store into the  {@link UDFContext} any information which the {@link LoadFunc} needs to store between various method invocations in thefront end and back end. A use case is to store  {@link RequiredFieldList} passed to it in  {@link LoadPushDown#pushProjection(RequiredFieldList)} foruse in the back end before returning tuples in  {@link LoadFunc#getNext()}. This method will be call before other methods in  {@link LoadFunc}
 * @param signature a unique signature to identify this LoadFunc
 */
</MethodComment>
            <ReturnType>void</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>signature</ParamName>
                    <ParamType>String</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>warn</MethodName>
            <MethodComment>/** 
 * Issue a warning.  Warning messages are aggregated and reported to the user.
 * @param msg String message of the warning
 * @param warningEnum type of warning
 */
</MethodComment>
            <ReturnType>void</ReturnType>
            <ParameterList>
                <Parameter>
                    <ParamName>msg</ParamName>
                    <ParamType>String</ParamType>
                </Parameter>
                <Parameter>
                    <ParamName>warningEnum</ParamName>
                    <ParamType>Enum</ParamType>
                </Parameter>
            </ParameterList>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke>PigHadoopLogger.getInstance();warn;[this, msg, warningEnum]</InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>getCacheFiles</MethodName>
            <MethodComment>/** 
 * Allow a LoadFunc to specify a list of files it would like placed in the distributed  cache. The default implementation returns null.
 * @return A list of files
 */
</MethodComment>
            <ReturnType>String</ReturnType>
            <ParameterList/>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
        <Method>
            <MethodName>getShipFiles</MethodName>
            <MethodComment>/** 
 * Allow a LoadFunc to specify a list of files located locally and would like to ship to backend  (through distributed cache). Check for  {@link FuncUtils} for utility function to facilitate itThe default implementation returns null.
 * @return A list of files
 */
</MethodComment>
            <ReturnType>String</ReturnType>
            <ParameterList/>
            <InnerVarList>
                <InnerVar></InnerVar>
            </InnerVarList>
            <InnerMethodInvokeList>
                <InnerMethodInvoke></InnerMethodInvoke>
            </InnerMethodInvokeList>
            <ThrowExceptionList>
                <ExceptionType></ExceptionType>
            </ThrowExceptionList>
        </Method>
    </MethodList>
</Class>